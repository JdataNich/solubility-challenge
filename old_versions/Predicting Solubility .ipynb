{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drug Solubility Predictor "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd #pandas is a dataframes library \n",
    "import numpy as np #numpy provides n-dim object support\n",
    "import matplotlib.pyplot as plt #plots data\n",
    "import os\n",
    "import sklearn \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "import seaborn as sns\n",
    "logisticRegr = LogisticRegression()\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import training and test data sets\n",
    "training_csv = pd.read_csv('C:/Users/joe/training_full_set.csv')\n",
    "test_csv = pd.read_csv('C:/Users/joe/test_full_set.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_csv['Log_S'] = 111\n",
    "#insert log s into test csv with values so it is not removed when concatenated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(106, 3753)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat((training_csv, test_csv),join='outer',axis=0, ignore_index=True) \n",
    "#concat the two data sets into one taking all columns from both data sets even if there is no value\n",
    "#remove the columns that are present in one data set not the other,n.b. this includes log s so need to fix that later\n",
    "df = df.dropna(axis=1, how='any')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting colum to name, target column to Log S\n",
    "# need to remove null colunms from data frame before doing this step?\n",
    "ID_col = ['NAME']\n",
    "target_col = ['Log_S']\n",
    "num_cols= list(set(list(df.columns))-set(ID_col)-set(target_col))\n",
    "x = df.loc[:,num_cols].values\n",
    "y = df.loc[:,['Log_S']].values\n",
    "# predicting solubility = y value, eerything else = x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().values.any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### at this point we have a data frame with training and test data with \n",
    "### matching columns and test data with arbitrary Log S values (111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0.29696646   0.09759001   0.         ...  -2.04982491  -0.13324272\n",
      "    0.        ]\n",
      " [ -1.07949484   0.09759001   0.         ...   0.81898144   4.91094607\n",
      "    0.        ]\n",
      " [ -1.30289956 -10.24695077   0.         ...   0.81898144  -0.13324272\n",
      "    0.        ]\n",
      " ...\n",
      " [ -0.92815617   0.09759001   0.         ...  -0.99063288  -0.13324272\n",
      "    0.        ]\n",
      " [  0.21048722   0.09759001   0.         ...  -0.47114284  -0.13324272\n",
      "    0.        ]\n",
      " [  0.86628815   0.09759001   0.         ...   1.57069385  -0.13324272\n",
      "    0.        ]]\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler(copy=True, with_mean=True, with_std=True)\n",
    "#instance the function for unit variance scaling \n",
    "(scaler.fit(x))\n",
    "scaled_x = (scaler.transform(x))\n",
    "print(scaled_x)\n",
    "# unit variance scalling on the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(106, 2211)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove low variance data from the x data set \n",
    "rm_variance = VarianceThreshold()\n",
    "variance_scaled_x = (rm_variance.fit_transform(scaled_x))\n",
    "variance_scaled_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x20b0f2e56a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pca = PCA(0.95)\n",
    "# could do PCA(0.9) or (n_components=)\n",
    "principalcomponents = pca.fit_transform(variance_scaled_x)\n",
    "#perfom pca on the x data set defined before as all values of the data frame except log s\n",
    "principalDf = pd.DataFrame(data = principalcomponents)\n",
    "#make a new data frame with the principal components \n",
    "plt.plot(pca.explained_variance_ratio_)\n",
    "pca.n_components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>Log_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>46.910191</td>\n",
       "      <td>-3.727184</td>\n",
       "      <td>-14.008413</td>\n",
       "      <td>9.420127</td>\n",
       "      <td>5.546700</td>\n",
       "      <td>5.647128</td>\n",
       "      <td>0.949502</td>\n",
       "      <td>-9.375622</td>\n",
       "      <td>-4.248683</td>\n",
       "      <td>-1.900821</td>\n",
       "      <td>...</td>\n",
       "      <td>2.770246</td>\n",
       "      <td>0.749563</td>\n",
       "      <td>2.085875</td>\n",
       "      <td>-1.538424</td>\n",
       "      <td>1.300617</td>\n",
       "      <td>0.553772</td>\n",
       "      <td>0.165452</td>\n",
       "      <td>-1.052876</td>\n",
       "      <td>-2.746454</td>\n",
       "      <td>4.018380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>51.393064</td>\n",
       "      <td>7.998942</td>\n",
       "      <td>6.477963</td>\n",
       "      <td>13.580215</td>\n",
       "      <td>4.507663</td>\n",
       "      <td>3.692471</td>\n",
       "      <td>9.105957</td>\n",
       "      <td>1.427779</td>\n",
       "      <td>3.988836</td>\n",
       "      <td>5.149498</td>\n",
       "      <td>...</td>\n",
       "      <td>6.565039</td>\n",
       "      <td>2.745897</td>\n",
       "      <td>-1.695614</td>\n",
       "      <td>-1.715112</td>\n",
       "      <td>4.859942</td>\n",
       "      <td>-1.539884</td>\n",
       "      <td>-0.474895</td>\n",
       "      <td>7.270967</td>\n",
       "      <td>3.774347</td>\n",
       "      <td>2.925669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>76.028090</td>\n",
       "      <td>-8.061326</td>\n",
       "      <td>11.724416</td>\n",
       "      <td>28.394829</td>\n",
       "      <td>25.684290</td>\n",
       "      <td>10.996146</td>\n",
       "      <td>26.865209</td>\n",
       "      <td>27.511559</td>\n",
       "      <td>12.801814</td>\n",
       "      <td>-19.514367</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.220173</td>\n",
       "      <td>-0.191760</td>\n",
       "      <td>0.249546</td>\n",
       "      <td>-0.640113</td>\n",
       "      <td>-0.561178</td>\n",
       "      <td>0.288803</td>\n",
       "      <td>0.133488</td>\n",
       "      <td>-0.239836</td>\n",
       "      <td>-0.833906</td>\n",
       "      <td>4.285827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>45.527367</td>\n",
       "      <td>13.763500</td>\n",
       "      <td>7.411321</td>\n",
       "      <td>17.016368</td>\n",
       "      <td>1.557770</td>\n",
       "      <td>1.278738</td>\n",
       "      <td>11.749037</td>\n",
       "      <td>-2.965313</td>\n",
       "      <td>3.718973</td>\n",
       "      <td>7.318301</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.621417</td>\n",
       "      <td>0.901082</td>\n",
       "      <td>-4.529994</td>\n",
       "      <td>6.901458</td>\n",
       "      <td>0.460375</td>\n",
       "      <td>2.995382</td>\n",
       "      <td>-0.339750</td>\n",
       "      <td>-2.896223</td>\n",
       "      <td>-3.708546</td>\n",
       "      <td>3.379708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>49.397355</td>\n",
       "      <td>-5.715870</td>\n",
       "      <td>12.375486</td>\n",
       "      <td>7.393553</td>\n",
       "      <td>-2.145998</td>\n",
       "      <td>-2.170914</td>\n",
       "      <td>-2.071853</td>\n",
       "      <td>-0.976115</td>\n",
       "      <td>-0.689757</td>\n",
       "      <td>0.332150</td>\n",
       "      <td>...</td>\n",
       "      <td>5.017396</td>\n",
       "      <td>-4.201899</td>\n",
       "      <td>-0.182921</td>\n",
       "      <td>2.638860</td>\n",
       "      <td>0.965781</td>\n",
       "      <td>-4.214924</td>\n",
       "      <td>-0.663757</td>\n",
       "      <td>4.542896</td>\n",
       "      <td>0.718003</td>\n",
       "      <td>4.936160</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0          1          2          3          4          5  \\\n",
       "0  46.910191  -3.727184 -14.008413   9.420127   5.546700   5.647128   \n",
       "1  51.393064   7.998942   6.477963  13.580215   4.507663   3.692471   \n",
       "2  76.028090  -8.061326  11.724416  28.394829  25.684290  10.996146   \n",
       "3  45.527367  13.763500   7.411321  17.016368   1.557770   1.278738   \n",
       "4  49.397355  -5.715870  12.375486   7.393553  -2.145998  -2.170914   \n",
       "\n",
       "           6          7          8          9    ...           41        42  \\\n",
       "0   0.949502  -9.375622  -4.248683  -1.900821    ...     2.770246  0.749563   \n",
       "1   9.105957   1.427779   3.988836   5.149498    ...     6.565039  2.745897   \n",
       "2  26.865209  27.511559  12.801814 -19.514367    ...    -0.220173 -0.191760   \n",
       "3  11.749037  -2.965313   3.718973   7.318301    ...    -3.621417  0.901082   \n",
       "4  -2.071853  -0.976115  -0.689757   0.332150    ...     5.017396 -4.201899   \n",
       "\n",
       "         43        44        45        46        47        48        49  \\\n",
       "0  2.085875 -1.538424  1.300617  0.553772  0.165452 -1.052876 -2.746454   \n",
       "1 -1.695614 -1.715112  4.859942 -1.539884 -0.474895  7.270967  3.774347   \n",
       "2  0.249546 -0.640113 -0.561178  0.288803  0.133488 -0.239836 -0.833906   \n",
       "3 -4.529994  6.901458  0.460375  2.995382 -0.339750 -2.896223 -3.708546   \n",
       "4 -0.182921  2.638860  0.965781 -4.214924 -0.663757  4.542896  0.718003   \n",
       "\n",
       "      Log_S  \n",
       "0  4.018380  \n",
       "1  2.925669  \n",
       "2  4.285827  \n",
       "3  3.379708  \n",
       "4  4.936160  \n",
       "\n",
       "[5 rows x 51 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finalDf = pd.concat([principalDf, df[['Log_S']]], axis = 1)\n",
    "#create a final data frame with the pc data frame and log s\n",
    "finalDf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>Log_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>8.943817</td>\n",
       "      <td>17.159376</td>\n",
       "      <td>0.885773</td>\n",
       "      <td>-13.521457</td>\n",
       "      <td>8.917472</td>\n",
       "      <td>5.518848</td>\n",
       "      <td>-1.341905</td>\n",
       "      <td>1.404028</td>\n",
       "      <td>-5.036560</td>\n",
       "      <td>-4.743340</td>\n",
       "      <td>...</td>\n",
       "      <td>1.202328</td>\n",
       "      <td>0.127022</td>\n",
       "      <td>5.021704</td>\n",
       "      <td>1.367421</td>\n",
       "      <td>-1.990583</td>\n",
       "      <td>0.401825</td>\n",
       "      <td>1.423931</td>\n",
       "      <td>3.544814</td>\n",
       "      <td>-0.460016</td>\n",
       "      <td>111.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>-73.741619</td>\n",
       "      <td>-21.998663</td>\n",
       "      <td>4.639965</td>\n",
       "      <td>4.350236</td>\n",
       "      <td>2.699055</td>\n",
       "      <td>12.187477</td>\n",
       "      <td>21.220140</td>\n",
       "      <td>-15.608070</td>\n",
       "      <td>-0.524662</td>\n",
       "      <td>0.984759</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.627841</td>\n",
       "      <td>-1.406555</td>\n",
       "      <td>-3.107369</td>\n",
       "      <td>-1.808877</td>\n",
       "      <td>-2.323556</td>\n",
       "      <td>2.503088</td>\n",
       "      <td>-1.439403</td>\n",
       "      <td>1.190296</td>\n",
       "      <td>1.331872</td>\n",
       "      <td>111.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>25.834991</td>\n",
       "      <td>1.165492</td>\n",
       "      <td>-16.230107</td>\n",
       "      <td>-2.696917</td>\n",
       "      <td>15.871886</td>\n",
       "      <td>0.793610</td>\n",
       "      <td>-15.065185</td>\n",
       "      <td>-0.316810</td>\n",
       "      <td>-2.417031</td>\n",
       "      <td>-9.694868</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.615614</td>\n",
       "      <td>3.741961</td>\n",
       "      <td>2.413137</td>\n",
       "      <td>5.239326</td>\n",
       "      <td>0.709498</td>\n",
       "      <td>-0.283868</td>\n",
       "      <td>1.906517</td>\n",
       "      <td>2.629007</td>\n",
       "      <td>1.315659</td>\n",
       "      <td>111.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>3.076549</td>\n",
       "      <td>4.569885</td>\n",
       "      <td>10.088122</td>\n",
       "      <td>-14.719860</td>\n",
       "      <td>-6.540791</td>\n",
       "      <td>1.907303</td>\n",
       "      <td>6.123158</td>\n",
       "      <td>1.200148</td>\n",
       "      <td>-3.525809</td>\n",
       "      <td>1.665112</td>\n",
       "      <td>...</td>\n",
       "      <td>0.181665</td>\n",
       "      <td>-1.146627</td>\n",
       "      <td>-0.237087</td>\n",
       "      <td>-2.245906</td>\n",
       "      <td>2.412937</td>\n",
       "      <td>1.065233</td>\n",
       "      <td>-0.972894</td>\n",
       "      <td>0.801709</td>\n",
       "      <td>-1.092182</td>\n",
       "      <td>111.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>-35.738936</td>\n",
       "      <td>-11.380707</td>\n",
       "      <td>2.062392</td>\n",
       "      <td>4.267574</td>\n",
       "      <td>8.305520</td>\n",
       "      <td>0.300280</td>\n",
       "      <td>-8.302934</td>\n",
       "      <td>5.802272</td>\n",
       "      <td>4.655866</td>\n",
       "      <td>6.908935</td>\n",
       "      <td>...</td>\n",
       "      <td>8.491050</td>\n",
       "      <td>4.281045</td>\n",
       "      <td>-0.732674</td>\n",
       "      <td>-0.608645</td>\n",
       "      <td>3.851596</td>\n",
       "      <td>-1.804798</td>\n",
       "      <td>6.132730</td>\n",
       "      <td>-2.907824</td>\n",
       "      <td>-1.203048</td>\n",
       "      <td>111.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0          1          2          3          4          5  \\\n",
       "101   8.943817  17.159376   0.885773 -13.521457   8.917472   5.518848   \n",
       "102 -73.741619 -21.998663   4.639965   4.350236   2.699055  12.187477   \n",
       "103  25.834991   1.165492 -16.230107  -2.696917  15.871886   0.793610   \n",
       "104   3.076549   4.569885  10.088122 -14.719860  -6.540791   1.907303   \n",
       "105 -35.738936 -11.380707   2.062392   4.267574   8.305520   0.300280   \n",
       "\n",
       "             6          7         8         9  ...          41        42  \\\n",
       "101  -1.341905   1.404028 -5.036560 -4.743340  ...    1.202328  0.127022   \n",
       "102  21.220140 -15.608070 -0.524662  0.984759  ...   -5.627841 -1.406555   \n",
       "103 -15.065185  -0.316810 -2.417031 -9.694868  ...   -7.615614  3.741961   \n",
       "104   6.123158   1.200148 -3.525809  1.665112  ...    0.181665 -1.146627   \n",
       "105  -8.302934   5.802272  4.655866  6.908935  ...    8.491050  4.281045   \n",
       "\n",
       "           43        44        45        46        47        48        49  \\\n",
       "101  5.021704  1.367421 -1.990583  0.401825  1.423931  3.544814 -0.460016   \n",
       "102 -3.107369 -1.808877 -2.323556  2.503088 -1.439403  1.190296  1.331872   \n",
       "103  2.413137  5.239326  0.709498 -0.283868  1.906517  2.629007  1.315659   \n",
       "104 -0.237087 -2.245906  2.412937  1.065233 -0.972894  0.801709 -1.092182   \n",
       "105 -0.732674 -0.608645  3.851596 -1.804798  6.132730 -2.907824 -1.203048   \n",
       "\n",
       "     Log_S  \n",
       "101  111.0  \n",
       "102  111.0  \n",
       "103  111.0  \n",
       "104  111.0  \n",
       "105  111.0  \n",
       "\n",
       "[5 rows x 51 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finalDf.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(74, 51)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# seperate out the data frame into training and test again. currently have n number of records with log s =111\n",
    "# need to seperate them into training and test again to generate model \n",
    "test_final_df = finalDf[finalDf.Log_S == 111]\n",
    "train_final_df = finalDf[finalDf.Log_S < 111]\n",
    "train_final_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create values for an array to use as input for logistic regression function\n",
    "ID_col = ['NAME']\n",
    "target_col = ['Log_S']\n",
    "num_cols= list(set(list(train_final_df.columns))-set(ID_col)-set(target_col))\n",
    "train_x = train_final_df.loc[:,num_cols].values\n",
    "train_y = train_final_df.loc[:,['Log_S']].values\n",
    "### and for test data\n",
    "ID_col = ['NAME']\n",
    "target_col = ['Log_S']\n",
    "num_cols= list(set(list(test_final_df.columns))-set(ID_col)-set(target_col))\n",
    "test_x = test_final_df.loc[:,num_cols].values\n",
    "test_y = test_final_df.loc[:,['Log_S']].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Prepared "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make an instance of the model \n",
    "# all parameters not specified are set to their defaults\n",
    "# default solver is incredibly slow which is why it was changed to 'lbfgs'\n",
    "logisticRegr = LogisticRegression(solver = 'lbfgs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='lbfgs', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_y = train_y.ravel()\n",
    "train_y = np.array(new_y).astype(int)\n",
    "logisticRegr.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 1, 4, 0, 3, 0, 1, 2, 3])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logisticRegr.predict(test_x[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logisticRegr.score(test_x, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='lbfgs', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# complete new approach just trying to do logistic regression on training\n",
    "# data, with y as log s and x as everything else (exceot the null columns\n",
    "# so using the data from post concatination but after being split and before \n",
    "# being scaled and variance \n",
    "logisticRegr.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
